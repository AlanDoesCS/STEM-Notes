---
title: Appendix 1. Formula Reference
nav_order: 100
parent: Mathematics
---
# Appendix 1. Formula Reference {-}

| **Exponents and Logarithms**                                    |                                                                |
| --------------------------------------------------------------- | -------------------------------------------------------------- |
| *Rules of Exponents*                                            | $a^m \cdot a^n = a^{m+n}$                                      |
|                                                                 | $a^m \div a^n = a^{m-n}$                                       |
|                                                                 | $(a^m)^n = a^{mn}$                                             |
|                                                                 | $a^0 = 1, \text{ for all } a \text{ in } \mathbb{C}, a \neq 0$ |
|                                                                 | $a^1 = a$                                                      |
|                                                                 | $a^{-m} = \frac{1}{a^m}$                                       |
|                                                                 | $a^{\frac{1}{m}} = \sqrt[m]{a}$                                |
|                                                                 | $a^{\frac{n}{m}} = (\sqrt[m]{a})^n$                            |
|                                                                 | $(ab)^n = a^n \cdot b^n$                                       |
|                                                                 | $\left(\frac{a}{b}\right)^n = \frac{a^n}{b^n}$                 |
| *Laws of Logarithms (real case: $a, x, y > 0$, and $a \neq 1$)* | $a^x = b \Longleftrightarrow \log_a{b}=x$                      |
|                                                                 | $\log_a{x} + \log_a{y} = \log_a{(xy)}$                         |
|                                                                 | $\log_a{x} - \log_a{y} = \log_a{(\frac{x}{y})}$                |
|                                                                 | $n \log_a{x} = \log_a{(x^n)}$                                  |

| **Sequences and Series**                           |                                                                                                                          |
| -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| *Sigma notation properties*                        |                                                                                                                          |
| Addition property                                  | $\sum_{n=1}^k{(a_n+b_n)}=\sum_{n=1}^k{a_n}+\sum_{n=1}^k{b_n}$                                                            |
| Constant Multiplication Property                   | $\sum_{n=1}^k{c \cdot u_n} = c \cdot \sum_{n=1}^k{u_n}$                                                                  |
| *Arithmetic Sequences and Series*                  |                                                                                                                          |
| The $n^{\text{th}}$ term of an arithmetic sequence | $u_n=u_1+(n-1)d$                                                                                                         |
| The sum of a finite arithmetic series              | $S_n = \frac{n}{2}(u_1 + u_n) \quad \text{OR} \quad S_n = \frac{n}{2}\left(2u_1 + (n - 1)d\right)$                       |
| *Geometric Sequences and Series*                   |                                                                                                                          |
| The $n^{\text{th}}$ term of a geometric sequence   | $u_n = u_1 r^{n-1}$                                                                                                      |
| The sum of a finite arithmetic series              | $S_n = \frac{u_1(r^n-1)}{r-1} \quad \text{OR} \quad S_n = \frac{u_1(1-r^n)}{1-r}, \quad \text{where} \quad r \neq 1$<br> |
| The sum of an infinite geometric series            | $S_{\infty}=\frac{u_1}{1-r}, \quad \text{where} \quad \lvert r \rvert < 1$                                               |

| **Finance**                    |                                                                           |
| ------------------------------ | ------------------------------------------------------------------------- |
| Interest paid                  | $\text{Interest Paid} = \text{Total Repayments} - \text{Amount Borrowed}$ |
| Effective annual interest rate | $r_{\text{eff}} = \left(1 + \frac{r}{n_c}\right)^{n_c} - 1$               |
| Compound interest (discrete)   | $V_f=V_0 \left(1 + \frac{r}{n_c}\right)^{n_{c}t}$                         |
| Compound interest (continuous) | $V_f = V_0 e^{rt}$                                                        |

| **Sets** |     |
| -------- | --- |
|          |     |

| **Sectors and Radians**         |                                   |
| ------------------------------- | --------------------------------- |
| Radians and degrees equivalence | $\pi \text{ radians} = 180^\circ$ |
| Arc length                      | $l=r \theta$                      |
| Sector area                     | $A=\frac{1}{2}r^2\theta$          |

| **Geometry**                                                                   |                                                                                                                           |
| ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------- |
| Distance between two points $a$ and $b$ in $n$-dimensional space               | $\sqrt{\sum_{i=1}^{n} \left( b_i - a_i \right)^2}$                                                                        |
| Midpoint of a line segment with endpoints $a$ and $b$ in $n$-dimensional space | $\left(\frac{1}{2}\left(a_i + b_i \right) \right)_{1 \leq i \leq n}$                                                      |
| *Spheres of radius $r$*                                                        |                                                                                                                           |
| Surface area                                                                   | $A=4 \pi r^2$                                                                                                             |
| Volume                                                                         | $V=\frac{4}{3} \pi r^3$                                                                                                   |
| *Pyramids of height $h$*                                                       |                                                                                                                           |
| Volume                                                                         | $V=\frac{1}{3}Ah$, where $A$ is the area of the base, and $h$ is perpendicular to the base plane                          |
| *Parallelogram*                                                                |                                                                                                                           |
| Area                                                                           | $A=\lvert\mathbf{v}\times\mathbf{w}\rvert$, where $\mathbf{v}$ and $\mathbf{w}$ are two adjacent sides of a parallelogram |

| **Trigonometry**           |                                              |
| -------------------------- | -------------------------------------------- |
| *Trigonometric Identities* |                                              |
|                            | $\cos^2\theta + \sin^2\theta = 1$            |
|                            | $\tan\theta = \frac{\sin\theta}{\cos\theta}$ |

| **Statistics**           |                                                               |
| ------------------------ | ------------------------------------------------------------- |
| Percentage error         | $\varepsilon = \lvert \frac{v_a - v_e}{v_e} \rvert \cdot 100$ |
| *Descriptive statistics* |                                                               |

| **Probability** |     |
| --------------- | --- |
|                 |     |

| **Random Variables and Probability Distributions** |     |
| -------------------------------------------------- | --- |
|                                                    |     |

| **Hypothesis Testing** |     |
| ---------------------- | --- |
|                        |     |

| **Functions**               |                                                                   |
| --------------------------- | ----------------------------------------------------------------- |
| Equation of a straight line | $y=mx+c \quad \text{OR} \quad y=m(x-x_1)+y_1$                     |
| Line of symmetry            | If $f(x)=ax^2+bx+c$, the axis of symmetry of is $x=-\frac{b}{2a}$ |
| Discriminant                | $\Delta = b^2 -4ac$                                               |

| **Differentiation** |     |
| ------------------- | --- |
|                     |     |

| **Integration** |     |
| --------------- | --- |
|                 |     |

| **Differential Equations** |     |
| -------------------------- | --- |
|                            |     |

| **Complex Numbers** |                                      |
| ------------------- | ------------------------------------ |
| Rectangular form    | $z = a + bi$                         |
| Polar form          | $z = r(\cos \theta + i\sin(\theta))$ |
| Exponential form    | $z = re^{i \theta}$                  |

| **Vectors**    |                                                                                                                                                                                                                               |
| -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Magnitude      | $\lvert \mathbf{v} \rvert = \sqrt{v_1^2 + v_2^2 + v_3^2}$                                                                                                                                                                     |
|                | $\text{OR} \quad \lvert \mathbf{v} \rvert = \sqrt{\sum_{i=1}^{n} v_i^2}$, where $v_i$ is the $i^\text{th}$ component of $\mathbf{v}$                                                                                          |
| Scalar product | $\mathbf{v} \cdot \mathbf{w} = \sum_{i=1}^n v_i w_i$                                                                                                                                                                          |
|                | $= \lvert\mathbf{v}\rvert\lvert\mathbf{w}\rvert\cos\theta$, where $\theta$ is the angle between $\mathbf{v}$ and $\mathbf{w}$                                                                                                 |
| Vector product | given $\mathbf{v}=\begin{pmatrix}v_1\\v_2\\v_3\end{pmatrix},$ and $\mathbf{w}=\begin{pmatrix}w_1\\w_2\\w_3\end{pmatrix}, \mathbf{v}\times \mathbf{w}=\begin{pmatrix}v_2w_3-v_3w_2\\v_3w_1-v_1w_3\\v_1w_2-v_2w_1\end{pmatrix}$ |
|                | $\lvert\mathbf{v}\times\mathbf{w}\rvert=\lvert\mathbf{v}\rvert\lvert\mathbf{w}\rvert\sin\theta$                                                                                                                               |

| **Matrices**                |                                                                                                                                                                                                |
| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Matrix addition             | $(A + B)_{ij} = a_{ij} + b_{ij}$                                                                                                                                                               |
| Matrix multiplication       | $(AB)_{ij} = \sum_{k=1}^n a_{ik} b_{kj}$                                                                                                                                                       |
|                             | $\text{OR} \quad AB = \left[ \sum_{k=1}^n a_{ik} b_{kj} \right]_{1 \le i \le m,\ 1 \le j \le p}$                                                                                               |
| Determinant of a 2×2 matrix | $\det \begin{pmatrix} a & b \\ c & d \end{pmatrix} = ad - bc$                                                                                                                                  |
| Determinant of a 3×3 matrix | $\det \begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix} = a(ei-fh)-b(di-fg)+c(dh-eg)$                                                                                          |
| Invertibility condition     | $A$ is invertible if $\det A \neq 0$                                                                                                                                                           |
| Power formula               | $A^n = PD^nP^{-1}$, where $A$ is a diagonalisible square matrix, $n \in \mathbb{N}$, $P$ is the matrix of eigenvectors of $A$, and $D$ is the diagonal matrix of the corresponding eigenvalues |
| *Transformation Matrices*   |                                                                                                                                                                                                |

| **Graph Theory**    |                                                                                                                                                                                |
| ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Adjacency matrices  | $a_{ij}=1$ if there exists an edge from vertex $i$ to vertex $j$, otherwise $a_{ij}=0$, for an unweighted graph.                                                               |
|                     | If the graph is weighted, $a_{ij}=w_{ij}$, where $w_{ij}$ represents the weight of the edge from $i$ to $j$, or $0$ if there exists no edge.                                   |
| Transition matrices | $a_{ij}$ is the probability of moving from vertex $i$ to vertex $j$ in a given step. *(**Note:** Some curricula define $a_{ij}$ as the probability of moving from $j$ to $i$)* |

| **Modelling**     |                                                          |
| ----------------- | -------------------------------------------------------- |
| Logistic function | $\frac{L}{1+Ce^{-kx}}$, where $L, C, k \in \mathbb{R}^+$ |
